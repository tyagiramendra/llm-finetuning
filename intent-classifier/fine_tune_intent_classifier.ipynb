{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dda1394-efe5-4dfd-8ba9-471f98671b9c",
   "metadata": {},
   "source": [
    "#### LLM Full Finetuning (flan-t5-small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6cadfa-3c60-45e9-87b1-5fdb58a74fc3",
   "metadata": {},
   "source": [
    "#### Intent classifier for Travel bot (text classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eaaf757-2065-481e-bb72-6b30420b9946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from huggingface_hub import HfFolder\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7bc07e6-f3d5-495d-8651-d2580036add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f07e36-2d2a-424b-bb6a-be85ee745004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(sample: Dataset, padding: str = \"max_length\") -> dict:\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [item for item in sample[\"utterance\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=max_source_length, padding=padding, truncation=True\n",
    "    )\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(\n",
    "        text_target=sample[\"intent\"],\n",
    "        max_length=max_target_length,\n",
    "        padding=padding,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(la if la != tokenizer.pad_token_id else -100) for la in label]\n",
    "            for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def postprocess_text(\n",
    "    preds: List[str], labels: List[str]\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"helper function to postprocess text\"\"\"\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, average=\"macro\"\n",
    "    )\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db07a330-f358-4cad-bf2a-570100d76ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59423eae-ff4f-468c-ba41-3a6c43f3f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"Cab Booking\": 0, \"Flight Booking\": 1, \"Fetch Booking \": 2, \"Modify Booking\": 3,\"FAQ\":4}\n",
    "id2label = {id: label for label, id in label2id.items()}\n",
    "\n",
    "def load_dataset(model_type: str = \"\") -> Dataset:\n",
    "    \"\"\"Load dataset.\"\"\"\n",
    "    dataset_intents_pandas = pd.read_excel(\n",
    "        \"Travel Assistant_MLUtterances.xlsx\",\n",
    "        header=None,\n",
    "        names=[\"utterance\",\"intent\"]\n",
    "    )\n",
    "\n",
    "    dataset_intents_pandas[\"intent\"] = dataset_intents_pandas[\"intent\"].astype(str)\n",
    "    if model_type == \"AutoModelForSequenceClassification\":\n",
    "        # Convert labels to integers\n",
    "        dataset_intents_pandas[\"intent\"] = dataset_intents_pandas[\"intent\"].map(\n",
    "            label2id\n",
    "        )\n",
    "\n",
    "    dataset_intents_pandas[\"utterance\"] = dataset_intents_pandas[\"utterance\"].astype(str)\n",
    "    dataset = Dataset.from_pandas(dataset_intents_pandas)\n",
    "    dataset = dataset.shuffle(seed=42)\n",
    "    dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00337c66-5383-4ce0-87bb-58fdab209abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dee4c9f8-626d-4cc4-b0c0-3305b3adb1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rtyagi\\AppData\\Local\\anaconda3\\envs\\finetune\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"google/flan-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fefc61b7-f733-4c23-b560-d34e5840d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Data to check calculate max token length for source(utterance) and target(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "775d6098-27e3-4068-b5e7-0fbc353b6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ea45e435794bf6b9325699c417fcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce90959c46a478d9a4d82ef2b73ecbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 4\n"
     ]
    }
   ],
   "source": [
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(\n",
    "    lambda x: tokenizer(x[\"utterance\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"utterance\", \"intent\"],\n",
    ")\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(\n",
    "    lambda x: tokenizer(x[\"intent\"], truncation=True),\n",
    "    batched=True,\n",
    "    remove_columns=[\"utterance\", \"intent\"],\n",
    ")\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")\n",
    "\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=REPOSITORY_ID,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,  # Overflows with fp16\n",
    "    learning_rate=3e-4,\n",
    "    num_train_epochs=10,\n",
    "    logging_dir=f\"{REPOSITORY_ID}/logs\",  # logging & evaluation strategies\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6c7692b-9d0b-483b-89bb-32df82bd7148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25c752e5bce40d8999ba9ca1c13bb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f329b6eb3a1847958e47104a7613cb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize Dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "        preprocess_function, batched=True, remove_columns=[\"utterance\", \"intent\"]\n",
    "    )\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "\n",
    "# load model from the hub\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8,\n",
    "    )\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        compute_metrics=compute_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3485f825-baa1-4463-8675-46132490d1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 03:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.550500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.058600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=180, training_loss=0.3958520162436697, metrics={'train_runtime': 234.6185, 'train_samples_per_second': 5.967, 'train_steps_per_second': 0.767, 'total_flos': 16265419161600.0, 'train_loss': 0.3958520162436697, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f911de9-172f-45f7-afa0-3b5c08d51bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "local_path_to_Save_model =\"D:/projects/llm-finetuning/intent-classifier/flan-t5-small-intent-classifier\"\n",
    "tokenizer.save_pretrained(local_path_to_Save_model)\n",
    "trainer.save_model(local_path_to_Save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca882499-a7fd-4751-b099-8b1f81d1a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Finetuned Model\n",
    "tokenizer_finetuned = AutoTokenizer.from_pretrained(local_path_to_Save_model)\n",
    "model_finetuned = AutoModelForSeq2SeqLM.from_pretrained(local_path_to_Save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2aecf-502c-48ea-9833-d0cb2a6c595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ced07081-8eea-49ac-a84a-e1f9cdad6fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(texts_to_classify: str):\n",
    "    \"\"\"Classify a batch of texts using the model.\"\"\"\n",
    "    inputs = tokenizer_finetuned(\n",
    "        texts_to_classify,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_finetuned.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=150,\n",
    "            num_beams=2,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "    predictions = [\n",
    "        tokenizer_finetuned.decode(output, skip_special_tokens=True) for output in outputs\n",
    "    ]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cedbdcda-00e6-446c-b9c7-51da2cc6dede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cab Booking']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Book cab from Noida to Gurugram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb75b1a9-7038-4348-a281-010e76d29bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dd02f31-4157-49b4-a1a0-aef5a381f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    \"\"\"Evaluate the model on the test dataset.\"\"\"\n",
    "    predictions_list, labels_list = [], []\n",
    "\n",
    "    batch_size = 16  # Adjust batch size based GPU capacity\n",
    "    num_batches = len(dataset[\"test\"]) // batch_size + (\n",
    "        0 if len(dataset[\"test\"]) % batch_size == 0 else 1\n",
    "    )\n",
    "    progress_bar = tqdm(total=num_batches, desc=\"Evaluating\")\n",
    "\n",
    "    for i in range(0, len(dataset[\"test\"]), batch_size):\n",
    "        batch_texts = dataset[\"test\"][\"utterance\"][i : i + batch_size]\n",
    "        batch_labels = dataset[\"test\"][\"intent\"][i : i + batch_size]\n",
    "\n",
    "        batch_predictions = classify(batch_texts)\n",
    "\n",
    "        predictions_list.extend(batch_predictions)\n",
    "        labels_list.extend([str(label) for label in batch_labels])\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    report = classification_report(labels_list, predictions_list)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45545d70-f326-4d99-af5a-431cb6f20240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274b2f414b574841b13adaaa4db1a2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "   Cab Booking       1.00      1.00      1.00        18\n",
      "           FAQ       1.00      1.00      1.00         8\n",
      " Fetch Booking       1.00      1.00      1.00         2\n",
      "Flight Booking       1.00      1.00      1.00         5\n",
      "Modify Booking       1.00      1.00      1.00         2\n",
      "\n",
      "      accuracy                           1.00        35\n",
      "     macro avg       1.00      1.00      1.00        35\n",
      "  weighted avg       1.00      1.00      1.00        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d4e8c-fae8-4af3-aedf-08a3cd31511b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
